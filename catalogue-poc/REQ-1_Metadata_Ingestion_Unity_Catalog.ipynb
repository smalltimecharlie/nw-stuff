{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "470e21c5",
   "metadata": {},
   "source": [
    "# üèóÔ∏è REQ-1: Register Datasets with Metadata at Ingestion\n",
    "\n",
    "This notebook demonstrates REQ-1 of our Unity Catalog governance requirements:\n",
    "\n",
    "> ‚úÖ \"As a platform engineer, I need to register datasets with metadata at ingestion. Metadata fields include data controller, processor, retention policy, and owner.\"\n",
    "\n",
    "Catalog: `unity_demo`  \n",
    "Schema: `governance_lab`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a324b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup catalog and schema\n",
    "spark.sql(\"CREATE CATALOG IF NOT EXISTS unity_demo\")\n",
    "spark.sql(\"USE CATALOG unity_demo\")\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS governance_lab\")\n",
    "spark.sql(\"USE SCHEMA governance_lab\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c34967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables with metadata\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# Employee table\n",
    "employees = [Row(id=1, name=\"Alice\", role=\"Engineer\"),\n",
    "             Row(id=2, name=\"Bob\", role=\"Analyst\")]\n",
    "spark.createDataFrame(employees).write.mode(\"overwrite\").saveAsTable(\"unity_demo.governance_lab.employee_records\")\n",
    "spark.sql(\"\"\"\n",
    "ALTER TABLE unity_demo.governance_lab.employee_records SET TBLPROPERTIES (\n",
    "  'data_controller' = 'HR Department',\n",
    "  'data_processor' = 'People Analytics Team',\n",
    "  'retention_policy' = '3y',\n",
    "  'owner' = 'hr@datacorp.com',\n",
    "  'data_agreement_url' = 's3://agreements/hr_policy.pdf',\n",
    "  'permitted_use' = 'internal only'\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Orders table\n",
    "orders = [Row(order_id=1001, customer_id=501, amount=250.75),\n",
    "          Row(order_id=1002, customer_id=502, amount=125.00)]\n",
    "spark.createDataFrame(orders).write.mode(\"overwrite\").saveAsTable(\"unity_demo.governance_lab.customer_orders\")\n",
    "spark.sql(\"\"\"\n",
    "ALTER TABLE unity_demo.governance_lab.customer_orders SET TBLPROPERTIES (\n",
    "  'data_controller' = 'Sales Department',\n",
    "  'data_processor' = 'E-Commerce Platform',\n",
    "  'retention_policy' = '2y',\n",
    "  'owner' = 'sales@datacorp.com',\n",
    "  'data_agreement_url' = 's3://agreements/sales_dpa.pdf',\n",
    "  'permitted_use' = 'analytics only'\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7a8f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm key metadata fields\n",
    "for tbl in [\"employee_records\", \"customer_orders\"]:\n",
    "    print(f\"\\n‚ñ∂Ô∏è Metadata for: {tbl}\")\n",
    "    spark.sql(f\"SHOW TBLPROPERTIES unity_demo.governance_lab.{tbl}\") \\\n",
    "        .filter(\"key in ('data_controller', 'data_processor', 'retention_policy', 'owner')\") \\\n",
    "        .show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
