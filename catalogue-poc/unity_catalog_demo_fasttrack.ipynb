{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1983a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unity Catalog PoC ‚Äì Rapid Test Suite\n",
    "# Catalog: `unity_demo`, Schema: `governance_lab`\n",
    "\n",
    "# Setup: Create catalog and schema\n",
    "spark.sql(\"CREATE CATALOG IF NOT EXISTS unity_demo\")\n",
    "spark.sql(\"USE CATALOG unity_demo\")\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS governance_lab\")\n",
    "spark.sql(\"USE SCHEMA governance_lab\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a36899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 1: employee_records\n",
    "from pyspark.sql import Row\n",
    "employees = [\n",
    "    Row(id=1, name=\"Alice\", role=\"Data Engineer\"),\n",
    "    Row(id=2, name=\"Bob\", role=\"Data Analyst\")\n",
    "]\n",
    "spark.createDataFrame(employees).write.mode(\"overwrite\").saveAsTable(\"unity_demo.governance_lab.employee_records\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "ALTER TABLE unity_demo.governance_lab.employee_records SET TBLPROPERTIES (\n",
    "  'data_controller' = 'HR Dept',\n",
    "  'data_processor' = 'People Analytics',\n",
    "  'retention_policy' = '3y',\n",
    "  'owner' = 'hr@datacorp.com',\n",
    "  'data_agreement_url' = 's3://agreements/hr_policy.pdf',\n",
    "  'permitted_use' = 'internal use only'\n",
    ")\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e6227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 2: customer_orders\n",
    "orders = [\n",
    "    Row(order_id=1001, customer_id=501, amount=250.75),\n",
    "    Row(order_id=1002, customer_id=502, amount=125.00)\n",
    "]\n",
    "spark.createDataFrame(orders).write.mode(\"overwrite\").saveAsTable(\"unity_demo.governance_lab.customer_orders\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "ALTER TABLE unity_demo.governance_lab.customer_orders SET TBLPROPERTIES (\n",
    "  'data_controller' = 'Sales Dept',\n",
    "  'data_processor' = 'E-Commerce Platform',\n",
    "  'retention_policy' = '2y',\n",
    "  'owner' = 'sales@datacorp.com',\n",
    "  'data_agreement_url' = 's3://agreements/sales_dpa.pdf',\n",
    "  'permitted_use' = 'analytics only'\n",
    ")\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ddef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 3: financial_transactions\n",
    "transactions = [\n",
    "    Row(txn_id=9001, account=\"A123\", value=990.00),\n",
    "    Row(txn_id=9002, account=\"A456\", value=1345.50)\n",
    "]\n",
    "spark.createDataFrame(transactions).write.mode(\"overwrite\").saveAsTable(\"unity_demo.governance_lab.financial_transactions\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "ALTER TABLE unity_demo.governance_lab.financial_transactions SET TBLPROPERTIES (\n",
    "  'data_controller' = 'Finance Dept',\n",
    "  'data_processor' = 'Accounting Software',\n",
    "  'retention_policy' = '6y',\n",
    "  'owner' = 'finance@datacorp.com',\n",
    "  'data_agreement_url' = 's3://agreements/finance_compliance.pdf',\n",
    "  'permitted_use' = 'regulatory + audit only'\n",
    ")\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f5a05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQ-2: View Controller/Processor info for each table\n",
    "for table in [\"employee_records\", \"customer_orders\", \"financial_transactions\"]:\n",
    "    print(f\"\\nüîç Metadata for: {table}\")\n",
    "    spark.sql(f\"SHOW TBLPROPERTIES unity_demo.governance_lab.{table}\") \\\n",
    "        .filter(\"key IN ('data_controller', 'data_processor')\") \\\n",
    "        .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29542e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQ-3: Simulate retention enforcement\n",
    "required_fields = ['data_controller', 'data_processor', 'retention_policy', 'owner']\n",
    "for table in [\"employee_records\", \"customer_orders\", \"financial_transactions\"]:\n",
    "    print(f\"\\nChecking retention policy for {table}\")\n",
    "    props = spark.sql(f\"SHOW TBLPROPERTIES unity_demo.governance_lab.{table}\").rdd.map(lambda r: (r.key, r.value)).collectAsMap()\n",
    "    missing = [k for k in required_fields if k not in props]\n",
    "    if missing:\n",
    "        print(\"‚ùå Missing required metadata fields:\", missing)\n",
    "    else:\n",
    "        print(\"‚úÖ All required metadata fields are present.\")\n",
    "        print(\"üìÖ Retention policy:\", props['retention_policy'])\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
