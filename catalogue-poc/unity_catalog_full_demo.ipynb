{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "407a6eac",
   "metadata": {},
   "source": [
    "# üß™ Unity Catalog Full Demo Notebook  \n",
    "Covers REQ-1 to REQ-3 (initial pass) with realistic metadata, enforcement logic, and Unity Catalog governance features.  \n",
    "Catalog: `unity_demo`, Schema: `governance_lab`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb4d16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "spark.sql(\"CREATE CATALOG IF NOT EXISTS unity_demo\")\n",
    "spark.sql(\"USE CATALOG unity_demo\")\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS governance_lab\")\n",
    "spark.sql(\"USE SCHEMA governance_lab\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74267688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 1: employee_records\n",
    "from pyspark.sql import Row\n",
    "employees = [\n",
    "    Row(id=1, name=\"Alice\", role=\"Engineer\"),\n",
    "    Row(id=2, name=\"Bob\", role=\"Analyst\"),\n",
    "]\n",
    "spark.createDataFrame(employees).write.mode(\"overwrite\").saveAsTable(\"unity_demo.governance_lab.employee_records\")\n",
    "spark.sql(\"\"\"\n",
    "ALTER TABLE unity_demo.governance_lab.employee_records SET TBLPROPERTIES (\n",
    "  'data_controller' = 'HR Dept',\n",
    "  'data_processor' = 'People Analytics',\n",
    "  'retention_policy' = '3y',\n",
    "  'owner' = 'hr@datacorp.com',\n",
    "  'data_agreement_url' = 's3://agreements/hr_policy.pdf',\n",
    "  'permitted_use' = 'internal use only'\n",
    ")\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc09c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 2: customer_orders\n",
    "orders = [\n",
    "    Row(order_id=1001, customer_id=501, amount=250.75),\n",
    "    Row(order_id=1002, customer_id=502, amount=125.00)\n",
    "]\n",
    "spark.createDataFrame(orders).write.mode(\"overwrite\").saveAsTable(\"unity_demo.governance_lab.customer_orders\")\n",
    "spark.sql(\"\"\"\n",
    "ALTER TABLE unity_demo.governance_lab.customer_orders SET TBLPROPERTIES (\n",
    "  'data_controller' = 'Sales Dept',\n",
    "  'data_processor' = 'E-Commerce Platform',\n",
    "  'retention_policy' = '2y',\n",
    "  'owner' = 'sales@datacorp.com',\n",
    "  'data_agreement_url' = 's3://agreements/sales_dpa.pdf',\n",
    "  'permitted_use' = 'analytics only'\n",
    ")\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9f4643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 3: financial_transactions\n",
    "transactions = [\n",
    "    Row(txn_id=9001, account=\"A123\", value=990.00),\n",
    "    Row(txn_id=9002, account=\"A456\", value=1345.50)\n",
    "]\n",
    "spark.createDataFrame(transactions).write.mode(\"overwrite\").saveAsTable(\"unity_demo.governance_lab.financial_transactions\")\n",
    "spark.sql(\"\"\"\n",
    "ALTER TABLE unity_demo.governance_lab.financial_transactions SET TBLPROPERTIES (\n",
    "  'data_controller' = 'Finance Dept',\n",
    "  'data_processor' = 'Accounting Software',\n",
    "  'retention_policy' = '6y',\n",
    "  'owner' = 'finance@datacorp.com',\n",
    "  'data_agreement_url' = 's3://agreements/finance_compliance.pdf',\n",
    "  'permitted_use' = 'regulatory + audit only'\n",
    ")\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f75aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQ-2: View metadata for controller/processor\n",
    "for table in [\"employee_records\", \"customer_orders\", \"financial_transactions\"]:\n",
    "    print(f\"\\nüîç {table} metadata:\")\n",
    "    spark.sql(f\"SHOW TBLPROPERTIES unity_demo.governance_lab.{table}\").filter(\"key LIKE 'data_%'\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2ece2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQ-3: Retention policy enforcement simulation\n",
    "required_keys = ['data_controller', 'data_processor', 'retention_policy', 'owner']\n",
    "for table in [\"employee_records\", \"customer_orders\", \"financial_transactions\"]:\n",
    "    print(f\"\\nChecking {table}\")\n",
    "    props = spark.sql(f\"SHOW TBLPROPERTIES unity_demo.governance_lab.{table}\").rdd.map(lambda r: (r.key, r.value)).collectAsMap()\n",
    "    missing = [k for k in required_keys if k not in props]\n",
    "    if missing:\n",
    "        print(\"‚ùå Missing fields:\", missing)\n",
    "    else:\n",
    "        print(\"‚úÖ Retention Policy:\", props['retention_policy'])\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
